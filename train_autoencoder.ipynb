{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "conv_autoencoder.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Training an autoencoder\n",
    "This notebook will train a basic autoencoder on the galaxy images from end-to-end."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob\n",
    "import tqdm\n",
    "\n",
    "# important for use on shared machine - comment these out if you're running locally.\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "\n",
    "from astropy.visualization import simple_norm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data loading and pre-processing\n",
    "This cell uses the same routine as before, except this time keeps the images as color.\n",
    "The `SUBSAMPLE` parameter controls what fraction of the dataset we use for the following trainings - if it's running too slowly, increase this to 2 or 4."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "14dRhGbC2gDv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def load_image_from_path(path):\n",
    "    \"\"\"\n",
    "    Decode a jpg image from the string filepath\n",
    "\n",
    "    :param path: Path to image\n",
    "    :return: 3D image tensor\n",
    "    \"\"\"\n",
    "    raw_img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(raw_img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, 'float32') # pre-normalises to 0,1\n",
    "    \n",
    "    return img.numpy()\n",
    "\n",
    "PATH_TO_DATA = \"data/final_28x28_proc\"\n",
    "\n",
    "train_filelist = glob.glob(os.path.join(PATH_TO_DATA, \"TRAIN\", \"*.jpg\"))\n",
    "val_filelist = glob.glob(os.path.join(PATH_TO_DATA, \"VAL\", \"*.jpg\"))\n",
    "\n",
    "# Adjust according to how long it's taking.\n",
    "SUBSAMPLE = 1\n",
    "\n",
    "if SUBSAMPLE > 1:\n",
    "    train_filelist = train_filelist[:len(train_filelist) // SUBSAMPLE]\n",
    "    val_filelist = val_filelist[:len(val_filelist) // SUBSAMPLE]\n",
    "    \n",
    "train_data = np.array([load_image_from_path(f) for f in tqdm.tqdm(train_filelist, desc='Processing training data')])\n",
    "val_data = np.array([load_image_from_path(f) for f in tqdm.tqdm(val_filelist, desc='Processing validation data')])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iasaWHYC30un",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "outputId": "d812de07-3d3f-49c8-9b39-5015a2957ef3"
   },
   "source": [
    "# plot some examples\n",
    "N_EXAMPLES = 4\n",
    "random_idx_seed = np.random.randint(0, len(val_data), N_EXAMPLES)\n",
    "\n",
    "fig, ax = plt.subplots(1, N_EXAMPLES, dpi=120)\n",
    "\n",
    "for i, idx in enumerate(random_idx_seed):\n",
    "  ax[i].imshow(train_data[idx], interpolation='lanczos')\n",
    "  ax[i].axis(\"off\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "03yPEcqH8ASP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# # dense auto-encoder\n",
    "# CODE_DIM = 128\n",
    "# inputs = tf.keras.Input(shape=(train_data.shape[1:]))\n",
    "# x = tf.keras.layers.Flatten()(inputs)\n",
    "# x = tf.keras.layers.Dense(units=32, activation='linear')(x)\n",
    "# x = tf.keras.layers.Dense(units=CODE_DIM, activation='linear', name='code')(x)\n",
    "# x = tf.keras.layers.Dense(units=32, activation='linear')(x)\n",
    "# x = tf.keras.layers.Dense(train_data.shape[1] * train_data.shape[2] * train_data.shape[3], activation='linear')(x)\n",
    "# outputs = tf.keras.layers.Reshape((train_data.shape[1:]))(x)\n",
    "# autoenc = tf.keras.Model(inputs=inputs, outputs=outputs, name='autoenc')\n",
    "# \n",
    "# autoenc.summary()\n",
    "\n",
    "input_img = tfk.Input(shape=(28, 28, 3))\n",
    "x = tfkl.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = tfkl.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = tfkl.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tfkl.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = tfkl.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = tfkl.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tfkl.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = tfkl.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = tfkl.MaxPooling2D((2, 2), padding='same', name='code')(x)\n",
    "x = tfkl.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same')(encoded)\n",
    "x = tfkl.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = tfkl.UpSampling2D((2, 2))(x)\n",
    "x = tfkl.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = tfkl.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = tfkl.UpSampling2D((2, 2))(x)\n",
    "x = tfkl.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = tfkl.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = tfkl.UpSampling2D((2, 2))(x)\n",
    "decoded = tfkl.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoenc = tfk.Model(input_img, decoded, name='autoenc')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compiling the model\n",
    "In this cell we 'compile' the model into a compute graph ready to execute. In each line we:\n",
    "* Specify the 'optimiser' algorithm [\\[see here\\]](https://keras.io/api/optimizers/) and the 'learning rate', i.e. the size of the steps we take.\n",
    "* The loss function: how well our model reconstructs the data - here we use the mean-squared error sum(square(x_pred - x_true))\n",
    "* Any other \"metrics\" we want to compute as we go. Here I've added the mean absolute error for example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TJa1JLJG8Dz8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "autoenc.compile(optimizer=opt, loss=loss, metrics=[\"mae\"])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training\n",
    "This cell does the model training - we pass a lot of arguments here, so step by step:\n",
    "* EarlyStopping: this monitors the validation loss, and stops training if it doesn't improve for 25 rounds of training. Upon stopping, it'll restore the best version of the model we found during training\n",
    "* `.fit()` calls the fitting routine on the `train_data`, with the inputs `x` and `y` being the same since we're training an autoencoder. We use the `val_data` as validation data, to monitor our progress and avoid overfitting. We use a `batch_size` of 16 - this is how many examples we train on at a time. The larger this is the more stable the gradient updates, but has a higher computational overhead. We have to attach the `EarlyStopping` routine we defined to the fitting routine, and we do this via callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-JBUhpmn9nSy",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "8026d191-fa5c-498e-aff5-ff8681c6af94"
   },
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "history = autoenc.fit(x=train_data, y=train_data, epochs=50, verbose=1, \n",
    "                    validation_data=(val_data, val_data), batch_size=64, callbacks=[early_stop,])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How did training go?\n",
    "We can here plot the loss and validation loss during training to see that everything went as expected."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "99Ddu7eW-KEo",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "outputId": "ddea36d0-ecf9-45b8-8ca6-339f093b1b70"
   },
   "source": [
    "plt.plot(history.epoch, history.history[\"loss\"], label='loss')\n",
    "plt.plot(history.epoch, history.history[\"val_loss\"], label='val_loss')\n",
    "plt.ylim(0.9*np.percentile(history.history[\"val_loss\"], 5), 1.1*np.percentile(history.history[\"val_loss\"], 95))\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.epoch, history.history[\"mae\"], label='mae')\n",
    "plt.plot(history.epoch, history.history[\"val_mae\"], label='val_mae')\n",
    "plt.ylim(0.9*np.percentile(history.history[\"val_mae\"], 5), 1.1*np.percentile(history.history[\"val_mae\"], 95))\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Did we succeed?\n",
    "Let's check how we did in encoding the galaxies. In this cell, we predict the outputs of the autoencoder on our validation set. If all has worked well, we should see galaxies!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LahJitBnHgSq",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "outputId": "de582247-88e8-4dc5-df18-f5241626ae91"
   },
   "source": [
    "reproduction = autoenc.predict(val_data)\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, dpi=300)\n",
    "\n",
    "random_idx_seed = np.random.randint(0, len(val_data), 5)\n",
    "\n",
    "for i, val in enumerate(random_idx_seed):\n",
    "  ax[0][i].imshow(val_data[val])\n",
    "  ax[0][i].axis(\"off\")\n",
    "  ax[1][i].imshow(reproduction[val])\n",
    "  ax[1][i].axis(\"off\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving and output\n",
    "\n",
    "These next few cells save the model in a usable format `.keras` for next steps, and print out the final validation loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4NnJzn8kIHJO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "autoenc.save(\"autoenc.keras\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"My best validation loss is {min(history.history['val_loss'])}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
