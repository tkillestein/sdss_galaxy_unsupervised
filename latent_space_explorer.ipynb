{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tfk.layers\n",
    "import os, glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import re\n",
    "\n",
    "# important for use on shared machine - comment these out if you're running locally.\n",
    "# tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "# tf.config.threading.set_intra_op_parallelism_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_path(path):\n",
    "    \"\"\"\n",
    "    Decode a jpg image from the string filepath\n",
    "\n",
    "    :param path: Path to image\n",
    "    :return: 3D image tensor\n",
    "    \"\"\"\n",
    "    raw_img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(raw_img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, 'float32') # pre-normalises to 0,1\n",
    "\n",
    "    return img.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading in the trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"autoenc.keras\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How do our reconstructions look?\n",
    "* Here we'll load in the validation data, encode the inputs, and look at how well we can reconstruct our galaxies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(\"data/final_28x28_proc/VAL/*.jpg\")\n",
    "imgs = np.array([load_image_from_path(r) for r in tqdm(filepaths, desc='Loading images', total=len(filepaths))])\n",
    "\n",
    "# This could take a while without GPU.\n",
    "reconst = model.predict(imgs, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some inputs and their reconstructions.\n",
    "N_PANELS = 5\n",
    "fig, ax = plt.subplots(2, N_PANELS, dpi=60)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=-0.2)\n",
    "\n",
    "for i, idx in enumerate(np.random.randint(0, len(imgs), N_PANELS)):\n",
    "    for j, arr in enumerate([imgs, reconst]):\n",
    "        ax[j][i].imshow(arr[idx], interpolation='lanczos')\n",
    "        ax[j][i].axis(\"off\")\n",
    "\n",
    "ax[0][0].set_title(\"Original\")\n",
    "ax[1][0].set_title(\"Reconst.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model surgery\n",
    "* In this next cell, we chop off the decoder of the model, and simply extract the 'embedding'/'code' layer. This contains the compressed representation of the input data we trained the model for."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the latent encodings from the autoencoder for the first 1024 stamps.\n",
    "encoder = tfk.Model(inputs=model.input, outputs=model.get_layer('code').output)\n",
    "testvecs = np.array(encoder(imgs)).reshape(len(imgs), -1)\n",
    "\n",
    "print(f\"Embedding shape is {testvecs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest-neighbour sanity check\n",
    "* Given a chosen image, do the nearest neighbours in latent space look similar? The answer should be yes, but worth checking before we proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_idx = 42\n",
    "N_NEAREST_NEIGHBOURS = 6\n",
    "\n",
    "fig, ax = plt.subplots(1, N_NEAREST_NEIGHBOURS+1, dpi=120)\n",
    "ax[0].imshow(imgs[chosen_idx])\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"Chosen\")\n",
    "\n",
    "# find N nearest neighbours in latent space according to Euclidean distance.\n",
    "nn_idxs = np.argsort(np.linalg.norm(testvecs[chosen_idx] - testvecs, axis=1))[1:N_NEAREST_NEIGHBOURS+1]\n",
    "\n",
    "for i, nn_idx in enumerate(nn_idxs):\n",
    "    ax[i+1].imshow(imgs[nn_idx])\n",
    "    ax[i+1].axis(\"off\")\n",
    "    ax[i+1].set_title(\"NN {}\".format(i+1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised clustering\n",
    "* Can we group galaxies based on their latent vectors? \n",
    "* Try two clustering methods, both don't require a set number of clusters. What sub-groupings can we find in the data?\n",
    "\n",
    "**NB** this section is largely experimental - we can discuss during the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, OPTICS\n",
    "clusterer = DBSCAN(min_samples=5).fit(testvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXAMPLES_PER_CLUSTER = 4\n",
    "\n",
    "for n in np.unique(clusterer.labels_):\n",
    "    members = np.argwhere(clusterer.labels_ == n).flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, N_EXAMPLES_PER_CLUSTER, dpi=60)\n",
    "    fig.suptitle(\"Cluster {} -- Total members: {}\".format(n+2, len(members)), y=0.7)\n",
    "    for i, idx in enumerate(np.random.choice(members.flatten(), N_EXAMPLES_PER_CLUSTER, replace=False)):\n",
    "        ax[i].imshow(imgs[idx])\n",
    "        ax[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = OPTICS(min_samples=5).fit(testvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXAMPLES_PER_CLUSTER = 5\n",
    "\n",
    "for n in np.unique(clusterer.labels_):\n",
    "    members = np.argwhere(clusterer.labels_ == n).flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, N_EXAMPLES_PER_CLUSTER, dpi=60)\n",
    "    fig.suptitle(\"Cluster {} -- Total members: {}\".format(n+2, len(members)), y=0.7)\n",
    "    for i, idx in enumerate(np.random.choice(members.flatten(), N_EXAMPLES_PER_CLUSTER, replace=False)):\n",
    "        ax[i].imshow(imgs[idx])\n",
    "        ax[i].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For you to try:\n",
    "* How does something like K-means (hint: `sklearn.cluster.KMeans`) perform?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem\n",
    "* End up in the regime with one large cluster, and many smaller clusters. If we set the minimum number of clusters too low, we end up with unrepresentative clusters.\n",
    "* Solution: hierarchical clustering. This essentially builds clusters from the bottom up, with clusters being merged if a certain metric (here Ward linkage) is met. This means that clusters do not end up with such disparate sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import kneighbors_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity_matr = kneighbors_graph(testvecs, n_neighbors=4, mode='connectivity')\n",
    "clusterer = AgglomerativeClustering(n_clusters=5, connectivity=connectivity_matr).fit(testvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EXAMPLES_PER_CLUSTER = 5\n",
    "for n in np.unique(clusterer.labels_):\n",
    "    members = np.argwhere(clusterer.labels_ == n).flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, N_EXAMPLES_PER_CLUSTER, dpi=180)\n",
    "    fig.suptitle(\"Cluster {} -- Total members: {}\".format(n+1, len(members)), y=0.65)\n",
    "    for i, idx in enumerate(np.random.choice(members.flatten(), N_EXAMPLES_PER_CLUSTER, replace=False)):\n",
    "        ax[i].imshow(imgs[idx])\n",
    "        ax[i].axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For you to try:\n",
    "* Agglomerative clustering is just one of these hierarchical clustering methods - try implementing HDBSCAN (hint `sklearn.cluster.HDBSCAN`) and see how it does."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does our clustering map in any way to morphology?\n",
    "* Let's take the galaxies with morphological information, strip away the subtypes and make some broad classes. \n",
    "  * E: ellipticals\n",
    "  * SB: barred spirals\n",
    "  * S: regular spirals\n",
    "  * Irr: irregulars -- not any of the above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphology = np.array([f.split(\"/\")[-1][:-4].split(\"_\")[-1] for f in filepaths])\n",
    "\n",
    "def amend_morphology_str(morphstr):\n",
    "    # Merge all ellipticals into one class\n",
    "    if re.search(\"E.\", morphstr):\n",
    "        return \"E\"\n",
    "    \n",
    "    # Merge all barred spirals into one class\n",
    "    if re.search(\"SB.\", morphstr):\n",
    "        return \"SB\"\n",
    "    \n",
    "    # Move transitional spirals into Irregular\n",
    "    if re.search(\"Sm\", morphstr):\n",
    "        return \"Irr\"\n",
    "    \n",
    "    # All spirals in the same class\n",
    "    if re.search(\"S.\", morphstr):\n",
    "        return \"S\"\n",
    "    \n",
    "    else:\n",
    "        return morphstr\n",
    "    \n",
    "morphology_corr = np.array([amend_morphology_str(s) for s in morphology])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in np.unique(morphology_corr):\n",
    "    print(\"{}: {} of {}\".format(m, (morphology_corr == m).sum(), len(morphology_corr)))\n",
    "    \n",
    "fig, ax = plt.subplots(1, len(np.unique(morphology_corr)))\n",
    "\n",
    "print(\"Example morphology classes\")\n",
    "for i, m in enumerate(np.unique(morphology_corr)):\n",
    "    idx = np.random.choice(np.argwhere(morphology_corr == m).flatten())\n",
    "    ax[i].imshow(imgs[idx])\n",
    "    ax[i].set_title(m)\n",
    "    ax[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.unique(clusterer.labels_):\n",
    "    mask1 = (clusterer.labels_ == c) \n",
    "    mask2 = mask1 & (morphology_corr != \"NA\")\n",
    "    print(\"Cluster {}: {} of {}\".format(c+1, mask2.sum(), mask1.sum()))\n",
    "    for m in np.unique(morphology_corr):\n",
    "        morph_mask = morphology_corr[mask2] == m\n",
    "        print(\"{:.1f} % of all {}\".format(100*morph_mask.sum() / (morphology_corr == m).sum(), m))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we really succeed here? Are any clusters overwhelmingly containing more of one type than another?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE\n",
    "* Let's apply t-stochastic neighbour embedding to reduce the dimensionality of the latent vectors. How well can we split the classes in this view? This is a bit like a non-linear PCA, which maps high-dimensional spaces to low-dimensional ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_vecs = TSNE(perplexity=200, n_jobs=-1, verbose=1).fit_transform(testvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"S\", \"E\", \"SB\", \"Irr\"]\n",
    "colors = [\"c\", \"y\", \"m\", \"k\"]\n",
    "for c, col in zip(classes, colors):\n",
    "    mask = morphology_corr == c\n",
    "    plt.scatter(tsne_vecs[mask,0], tsne_vecs[mask,1], s=3, c=col, label=c)\n",
    "plt.xlabel(\"Latent dimension 1\")\n",
    "plt.ylabel(\"Latent dimension 2\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did we do?\n",
    "* There is a clear splitting between ellipticals and spirals.\n",
    "* Splitting barred and unbarred spirals much harder - maybe this is a resolution issue?\n",
    "* Irregulars broadly lie on the edge of the point cloud -- they are irregular!\n",
    "\n",
    "##### Despite the not exceptional performance, let's explore some clustering metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert \n",
    "morph_labels = morphology_corr[morphology_corr != \"NA\"]\n",
    "morph_labels[morph_labels == \"E\"] = 0\n",
    "morph_labels[morph_labels == \"S\"] = 1\n",
    "morph_labels[morph_labels == \"SB\"] = 2\n",
    "morph_labels[morph_labels == \"Irr\"] = 3\n",
    "clust_labels = clusterer.labels_[morphology_corr != \"NA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Silhouette score: {:.3f}\".format(metrics.silhouette_score(testvecs, clusterer.labels_)))\n",
    "print(\"Mutual information score: {:.3f}\".format(metrics.mutual_info_score(morph_labels, clust_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### So what is the takeaway here?\n",
    "* Non-linear dimensionality reduction is more powerful, but more involved.\n",
    "* Clustering: not guaranteed to generate meaningful representations (why?)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
