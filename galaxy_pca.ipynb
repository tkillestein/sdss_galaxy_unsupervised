{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Galaxy PCA\n",
    "This notebook will take you through the steps of performing PCA on the galaxy dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b21652f2aa4dd4cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88b191379e8db9e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob\n",
    "import tqdm\n",
    "import re\n",
    "\n",
    "PATH_TO_DATA = \"data/final_28x28_proc\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data ingest\n",
    "This cell defines a function to load in the JPG-encoded images into a form we can easily use. This cell yields a set of images, shape (width x height x channels) which we concatenate along a new axis to get a stack of images, shape (image x width x height x channels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "783708e0c01fc16a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_image_from_path(path):\n",
    "    \"\"\"\n",
    "    Decode a jpg image from the string filepath\n",
    "\n",
    "    :param path: Path to image\n",
    "    :return: 3D image tensor\n",
    "    \"\"\"\n",
    "    raw_img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(raw_img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, 'float32') # pre-normalises to 0,1\n",
    "    \n",
    "    return img.numpy()\n",
    "\n",
    "filelist = glob.glob(os.path.join(PATH_TO_DATA, \"*\", \"*.jpg\"))\n",
    "all_data = np.array([load_image_from_path(f) for f in tqdm.tqdm(filelist, desc='Processing data')])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e831f935cad64628"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-processing\n",
    "In this cell, we need to convert the images to greyscale to make the upcoming analysis easier. `all_data` needs to now have shape (images x width x height)\n",
    "*Note:* this code will fail until you fix it!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20116b7b331e0e55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "monochrome_data = \"...\" # write code here - either to take the mean, or pick out an individual component\n",
    "\n",
    "fig, axes = plt.subplots(1, 5)\n",
    "\n",
    "randidx = np.random.randint(0, len(monochrome_data), size=5)\n",
    "\n",
    "for ax, example in zip(axes, randidx):\n",
    "    ax.imshow(monochrome_data[example], cmap='Greys')\n",
    "    ax.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b96acec7c5d746b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PCA\n",
    "In these next cells, we'll perform PCA on the dataset we've now made monochrome. Due to how PCA works, we need to flatten the images into a 2D vector, effectively converting them from n_images x 28 x 28 -> n_images x 784. We'll undo this afterwards!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da06b668c732f3e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# For sklearn we need to flatten all non-leading dimensions - don't worry, this isn't permanent!\n",
    "pca_data = monochrome_data.reshape(len(monochrome_data), -1)\n",
    "print(\"PCA input has shape {}\".format(pca_data.shape))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1729a3eb1c1c9b79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Actually doing the PCA\n",
    "In this cell, we apply PCA to the data using the `PCA` routine from `scikit-learn`. We truncate at the first 20 principal components initially, but you can change this yourself to access the higher-order components.\n",
    "\n",
    "For the `eigengalaxies` variable, we undo our initial flattening, reshaping the vectors to the original 28 x 28 image format. The first plot shows how the eigengalaxies look, and the second plot shows the fraction of explained variance (i.e. how good each component is at capturing the data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc9b8fc25c46ae50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# N most prominent components, for example\n",
    "pca_model = PCA(n_components=20).fit(pca_data)\n",
    "\n",
    "eigengalaxies = pca_model.components_.reshape(pca_model.n_components, 28, 28)\n",
    "\n",
    "fig, axes = plt.subplots(3, pca_model.n_components // 3)\n",
    "\n",
    "for idx, (ax, eigengalaxy) in enumerate(zip(axes.ravel(), eigengalaxies)):\n",
    "    ax.imshow(eigengalaxy, cmap='Greys')\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"PC {idx}\")\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "plt.plot(1 - pca_model.explained_variance_ratio_)\n",
    "plt.xlabel(\"Principal component\")\n",
    "plt.ylabel(\"Fraction of explained variance\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4148e012ee38f5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How do galaxies look with truncated principal components?\n",
    "* Change the value of `n_components` in the cell below, and observe how the reconstruction behaves.\n",
    "\n",
    "* The line `truncated_imgs = np.einsum(\"ij,jkl->ikl\", pca_coeffs, eigengalaxies)` does a lot in one line, and uses [Einstein summation](https://en.wikipedia.org/wiki/Einstein_notation) (for those familiar) to compactly write the below steps\n",
    "   * `pca_coeffs` has shape (`n_images`, `n_components`)\n",
    "   * `eigengalaxies` has shape (`n_components`, `width`, `height`)\n",
    "   * For each of `n_images`, we do sum(coefficient_n * component_n) -> i.e. principal component 1 * eigengalaxy 1 + principal component 2 * eigengalaxy 2, building up our final image(s) one principal component at a time\n",
    "   * This is effectively the `dot product` between the eigenvalues and eigenvectors, but because of the way the dimensions are oriented it's a little more work."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb09a7022107ff61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_result = PCA(n_components=784).fit(pca_data)\n",
    "pca_coeffs = pca_result.transform(pca_data)\n",
    "eigengalaxies = pca_result.components_.reshape(pca_result.n_components, 28, 28)\n",
    "\n",
    "print(pca_coeffs.shape)\n",
    "print(eigengalaxies.shape)\n",
    "\n",
    "randidx = np.random.randint(0, len(monochrome_data), size=5)\n",
    "\n",
    "truncated_imgs = np.einsum(\"ij,jkl->ikl\", pca_coeffs, eigengalaxies)\n",
    "\n",
    "fig, axes = plt.subplots(3, 5)\n",
    "\n",
    "fig.suptitle(f\"PC <= {pca_result.n_components}\")\n",
    "\n",
    "for idx, example in zip(range(5), randidx):\n",
    "    axes[0][idx].imshow(monochrome_data[example], cmap='Greys')\n",
    "    axes[1][idx].imshow(truncated_imgs[example], cmap='Greys')\n",
    "    axes[2][idx].imshow(monochrome_data[example] - truncated_imgs[example], cmap='Greys', vmin=-1, vmax=1)\n",
    "    axes[0][idx].axis(\"off\")    \n",
    "    axes[1][idx].axis(\"off\")\n",
    "    axes[2][idx].axis(\"off\")\n",
    "\n",
    "axes[0][0].set_ylabel(\"Original\")\n",
    "axes[1][0].set_ylabel(\"Truncated\")\n",
    "axes[2][0].set_ylabel(\"Residual\")\n",
    "    \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2dd9d73d6c053da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How does the PCA latent space look?\n",
    "In the below cells, we extract the morphology string from the file name - the `amend_morphology_str` function matches on filenames, and returns a normal set of strings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93444496e9f97148"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "morphology = np.array([f.split(\"/\")[-1][:-4].split(\"_\")[-1] for f in filelist])\n",
    "\n",
    "def amend_morphology_str(morphstr):\n",
    "    # Merge all ellipticals into one class\n",
    "    if re.search(\"E.\", morphstr):\n",
    "        return \"E\"\n",
    "    \n",
    "    # Merge all barred spirals into one class\n",
    "    if re.search(\"SB.\", morphstr):\n",
    "        return \"SB\"\n",
    "    \n",
    "    # Move transitional spirals into Irregular\n",
    "    if re.search(\"Sm\", morphstr):\n",
    "        return \"Irr\"\n",
    "    \n",
    "    # All spirals in the same class\n",
    "    if re.search(\"S.\", morphstr):\n",
    "        return \"S\"\n",
    "    \n",
    "    else:\n",
    "        return morphstr\n",
    "    \n",
    "morphology_corr = np.array([amend_morphology_str(s) for s in morphology])\n",
    "\n",
    "for m in np.unique(morphology_corr):\n",
    "    print(\"{}: {} of {}\".format(m, (morphology_corr == m).sum(), len(morphology_corr)))\n",
    "    \n",
    "fig, ax = plt.subplots(1, len(np.unique(morphology_corr)))\n",
    "\n",
    "print(\"Example morphology classes\")\n",
    "for i, m in enumerate(np.unique(morphology_corr)):\n",
    "    idx = np.random.choice(np.argwhere(morphology_corr == m).flatten())\n",
    "    ax[i].imshow(all_data[idx])\n",
    "    ax[i].set_title(m)\n",
    "    ax[i].axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff6be676387799ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_coeffs = PCA(n_components=2).fit_transform(pca_data)\n",
    "\n",
    "for group in ['E', 'Irr', 'S', 'SB', 'NA']:\n",
    "    subset = morphology_corr == group\n",
    "    \n",
    "    plt.scatter(*pca_coeffs[subset].T, s=1, label=group)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a47ad37045dce164"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Does PCA divide the classes well?\n",
    "* The plot below shows PC1 and PC2, and colours the points by their label.\n",
    "* Try changing the groups present in the list below, and see which classes can be distinguished from each other. Does it make sense?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b90833ceb8af5f2c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_coeffs = PCA(n_components=2).fit_transform(pca_data)\n",
    "\n",
    "for group in ['E', 'S']:\n",
    "    subset = morphology_corr == group\n",
    "    \n",
    "    plt.scatter(*pca_coeffs[subset].T, s=1, label=group)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b36dfa68f88b6c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
